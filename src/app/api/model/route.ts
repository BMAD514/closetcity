import { NextRequest, NextResponse } from 'next/server';
import { r2Put, sha256, generateId } from '@/lib/utils';
import { Env, ModelRequest, ModelResponse } from '@/lib/types';
import { getDefaultProvider } from '@/lib/tryon';
import { checkRateLimitEdge } from '@/lib/ratelimit';
import { getRequestContext } from '@cloudflare/next-on-pages';

export const runtime = 'edge';

export async function POST(request: NextRequest): Promise<NextResponse<ModelResponse>> {
  try {
    const env = getRequestContext().env as Env;

    if (!env.DB || !env.R2 || !env.GEMINI_API_KEY) {
      return NextResponse.json(
        { success: false, error: 'Required services not configured', url: '', cached: false, code: 'CONFIG_MISSING' },
        { status: 500 }
      );
    }

    const rl = await checkRateLimitEdge((env as Env).RL_KV, request as unknown as Request, 10);
    if (rl.exceeded) {
      return NextResponse.json(
        { success: false, error: 'Rate limit exceeded', url: '', cached: false, code: 'RATE_LIMIT' },
        { status: 429, headers: { 'Retry-After': String(rl.retryAfterSeconds ?? 0) } }
      );
    }

    const body: ModelRequest = await request.json();
    const { userImageUrl } = body || {} as ModelRequest;

    if (!userImageUrl) {
      return NextResponse.json(
        { success: false, error: 'Missing required field: userImageUrl', url: '', cached: false, code: 'BAD_REQUEST' },
        { status: 400 }
      );
    }

    const promptVersion = env.PROMPT_VERSION || 'v1';
    const cacheInput = `${promptVersion}|${userImageUrl}`;
    const cacheKey = await sha256(cacheInput);

    const cached = await env.DB.prepare('SELECT image_url FROM model_cache WHERE cache_key = ?').bind(cacheKey).first();
    if (cached) {
      console.log(`Cache hit for model: ${cacheKey}`);
      return NextResponse.json({ success: true, url: cached.image_url as string, cached: true, cacheHit: true as unknown as never });
    }

    console.log(`Cache miss for model: ${cacheKey}, calling provider.generateModel`);
    const provider = getDefaultProvider(env.GEMINI_API_KEY);
    const result = await provider.generateModel(userImageUrl);

    if (!result?.dataBase64) {
      return NextResponse.json(
        { success: false, error: 'No image generated by AI', url: '', cached: false, code: 'AI_FAILURE' },
        { status: 500 }
      );
    }

    const imageData = atob(result.dataBase64);
    const imageBytes = new Uint8Array(imageData.length);
    for (let i = 0; i < imageData.length; i++) imageBytes[i] = imageData.charCodeAt(i);

    const resultId = generateId();
    const resultKey = `model/${resultId}.webp`;
    const resultUrl = await r2Put(env.R2, resultKey, imageBytes, 'image/webp');

    await env.DB.prepare('INSERT INTO model_cache (cache_key, image_url, prompt_version) VALUES (?, ?, ?)')
      .bind(cacheKey, resultUrl, promptVersion)
      .run();

    console.log(`Generated and cached model result: ${resultKey}`);

    return NextResponse.json({ success: true, url: resultUrl, cached: false, cacheHit: false as unknown as never });
  } catch (error) {
    console.error('Model generate error:', error);
    return NextResponse.json(
      { success: false, error: error instanceof Error ? error.message : 'Model generation failed', url: '', cached: false, code: 'INTERNAL_ERROR' },
      { status: 500 }
    );
  }
}

